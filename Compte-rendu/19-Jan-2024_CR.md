# COMPTE RENDU DU 19/01/2024

## Organisation
- Préparer ordre du jour avant chaque rdv, 24h à l’avance (ce qu’on a fait, ce que vont veux faire, les sujets que l’on veut traiter…)
- On garde le même créneaux (Vendredi 14h45-15h45) tout le semestre

## Elements du sujet
* S’avancer sur AROB sera utile
* TD-MPC
    * “Apprendre un modèle qui est la dynamique du système” : Si on lui donne un état et l’env, il peut prédire la situation optimale suivante (en faisant l’action)
    * Cross-entropy method ?
    * Différence temporelle : mécanisme d’RL, qui permet du juger l’efficacité d’une position ?
    * En gros, on planifie sur un certain horizon (par exemple les 6 prochains coups d’échecs), et on déduit la meilleure action (la valeur d’un état et d’env doit être appris ou fournis)
    * Comment est-ce qu’on apprend à partir d’image ? (C’est le but)
        * L’article optimise la loss function
        * BUT DU PROJET => Implémentation de cela sous BBRL
    * BBRL => Lib de RL avec réseaux de neurones.
    * Il existe des dépôts GitHub avec une implémentation qui marche

## Etapes du projet:
1. Comprendre le RL
2. Comprendre l’article
3. Comprendre les implémentations existantes
4. Implémenter dans BBRL
5. Tester l’implémentation

## Conseil
Prendre de l'avance tout de suite sur le projet, car la fin du semestre sera chargé

## POUR LA SEMAINE PRO:
- Regarder cours RL tabulaire, voir avec réseaux de neurones (M2) (YouTube playlist)
- Lire l’article TD-MPC, et noter tout ce qui est incompris, pour poser des questions lors du prochain RDV
- Chercher le depo GitHub des auteurs TD-MPC (et tester), Si besoin, utiliser machine de la PPTI (demander les libs)
